import asyncio
import random
from typing import Optional, Dict, Any, Tuple

from aiohttp import ClientSession, ClientTimeout, ClientError

from manager import manager

logger = manager.logger

# å¸¸é‡å®šä¹‰
DEFAULT_TIMEOUT = ClientTimeout(total=30.0)
PROMPT_TIMEOUT = 15
HISTORY_TIMEOUT = 10
MAX_RETRIES = 30
RETRY_DELAY = 7
DEFAULT_SEED_RANGE = (0, 0xFFFFFFFFFFFFFFFF)

# å·¥ä½œæµé…ç½®
WORKFLOW_CONFIG = {
    "vae_name": "ae.safetensors",
    "sampler_name": "euler_ancestral",
    "scheduler": "sgm_uniform",
    "guidance": 3.5,
    "max_shift": 1.15,
    "base_shift": 0.5,
    "model_path": "svdq-int4-flux.1-dev",
    "text_encoder1": "clip-vit-large-patch14/model.safetensors",
    "text_encoder2": "clip_l.safetensors",
    "lora1": "flux/PinkieFluxProUltraFantasia.safetensors",
    "lora2": "flux/flux1-turbo.safetensors",
}


class ComfyAPIError(Exception):
    """ComfyUI API ç›¸å…³é”™è¯¯çš„åŸºç±»"""

    pass


class WorkflowSubmissionError(ComfyAPIError):
    """å·¥ä½œæµæäº¤å¤±è´¥é”™è¯¯"""

    pass


class ImageGenerationTimeoutError(ComfyAPIError):
    """å›¾ç‰‡ç”Ÿæˆè¶…æ—¶é”™è¯¯"""

    pass


class ImageDownloadError(ComfyAPIError):
    """å›¾ç‰‡ä¸‹è½½å¤±è´¥é”™è¯¯"""

    pass


def _parse_image_size(size: str) -> Tuple[int, int]:
    """
    è§£æå›¾ç‰‡å°ºå¯¸å­—ç¬¦ä¸²

    Args:
        size: å°ºå¯¸å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "widthxheight"

    Returns:
        å…ƒç»„ (width, height)

    Raises:
        ValueError: æ ¼å¼é”™è¯¯æ—¶æŠ›å‡º
    """
    try:
        width, height = map(int, size.lower().split("x"))
        return width, height
    except ValueError:
        raise ValueError("å°ºå¯¸æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º 'widthxheight'ï¼Œä¾‹å¦‚ '512x512'")


def _create_workflow(
    prompt: str, width: int, height: int, steps: int, seed: Optional[int] = None
) -> Dict[str, Any]:
    """
    åˆ›å»º ComfyUI å·¥ä½œæµé…ç½®

    Args:
        prompt: æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        steps: é‡‡æ ·æ­¥æ•°
        seed: éšæœºç§å­ï¼Œå¦‚æœä¸º None åˆ™éšæœºç”Ÿæˆ

    Returns:
        å·¥ä½œæµé…ç½®å­—å…¸
    """
    if seed is None:
        seed = random.randint(*DEFAULT_SEED_RANGE)

    return {
        "6": {
            "inputs": {
                "text": prompt,
                "clip": ["44", 0],
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Positive Prompt)"},
        },
        "8": {
            "inputs": {"samples": ["13", 0], "vae": ["10", 0]},
            "class_type": "VAEDecode",
            "_meta": {"title": "VAE Decode"},
        },
        "10": {
            "inputs": {"vae_name": WORKFLOW_CONFIG["vae_name"]},
            "class_type": "VAELoader",
            "_meta": {"title": "Load VAE"},
        },
        "13": {
            "inputs": {
                "noise": ["25", 0],
                "guider": ["22", 0],
                "sampler": ["16", 0],
                "sigmas": ["17", 0],
                "latent_image": ["27", 0],
            },
            "class_type": "SamplerCustomAdvanced",
            "_meta": {"title": "SamplerCustomAdvanced"},
        },
        "16": {
            "inputs": {"sampler_name": WORKFLOW_CONFIG["sampler_name"]},
            "class_type": "KSamplerSelect",
            "_meta": {"title": "KSamplerSelect"},
        },
        "17": {
            "inputs": {
                "scheduler": WORKFLOW_CONFIG["scheduler"],
                "steps": steps,
                "denoise": 1,
                "model": ["30", 0],
            },
            "class_type": "BasicScheduler",
            "_meta": {"title": "BasicScheduler"},
        },
        "22": {
            "inputs": {"model": ["30", 0], "conditioning": ["26", 0]},
            "class_type": "BasicGuider",
            "_meta": {"title": "BasicGuider"},
        },
        "25": {
            "inputs": {"noise_seed": seed},
            "class_type": "RandomNoise",
            "_meta": {"title": "RandomNoise"},
        },
        "26": {
            "inputs": {
                "guidance": WORKFLOW_CONFIG["guidance"],
                "conditioning": ["6", 0],
            },
            "class_type": "FluxGuidance",
            "_meta": {"title": "FluxGuidance"},
        },
        "27": {
            "inputs": {"width": width, "height": height, "batch_size": 1},
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "EmptySD3LatentImage"},
        },
        "30": {
            "inputs": {
                "max_shift": WORKFLOW_CONFIG["max_shift"],
                "base_shift": WORKFLOW_CONFIG["base_shift"],
                "width": width,
                "height": height,
                "model": ["47", 0],
            },
            "class_type": "ModelSamplingFlux",
            "_meta": {"title": "ModelSamplingFlux"},
        },
        "44": {
            "inputs": {
                "model_type": "flux",
                "text_encoder1": WORKFLOW_CONFIG["text_encoder1"],
                "text_encoder2": WORKFLOW_CONFIG["text_encoder2"],
                "t5_min_length": 512,
                "use_4bit_t5": "disable",
                "int4_model": "none",
            },
            "class_type": "NunchakuTextEncoderLoader",
            "_meta": {"title": "Nunchaku Text Encoder Loader"},
        },
        "45": {
            "inputs": {
                "model_path": WORKFLOW_CONFIG["model_path"],
                "cache_threshold": 0,
                "attention": "nunchaku-fp16",
                "cpu_offload": "auto",
                "device_id": 0,
                "data_type": "float16",
                "i2f_mode": "enabled",
            },
            "class_type": "NunchakuFluxDiTLoader",
            "_meta": {"title": "Nunchaku FLUX DiT Loader"},
        },
        "46": {
            "inputs": {
                "lora_name": WORKFLOW_CONFIG["lora1"],
                "lora_strength": 1,
                "model": ["45", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX.1 LoRA Loader"},
        },
        "47": {
            "inputs": {
                "lora_name": WORKFLOW_CONFIG["lora2"],
                "lora_strength": 1.0,
                "model": ["46", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX.1 LoRA Loader"},
        },
        "48": {
            "inputs": {
                "filename_prefix": "ComfyUI",
                "filename_keys": "sampler_name, cfg, steps, %F %H-%M-%S",
                "foldername_prefix": "",
                "foldername_keys": "flux",
                "delimiter": "-",
                "save_job_data": "disabled",
                "job_data_per_image": False,
                "job_custom_text": "",
                "save_metadata": False,
                "counter_digits": 4,
                "counter_position": "last",
                "one_counter_per_folder": True,
                "image_preview": True,
                "output_ext": ".avif",
                "quality": 90,
                "images": ["8", 0],
            },
            "class_type": "SaveImageExtended",
            "_meta": {"title": "ğŸ’¾ Save Image Extended"},
        },
    }


async def _submit_workflow(
    session: ClientSession, endpoint: str, workflow: Dict[str, Any]
) -> str:
    """
    æäº¤å·¥ä½œæµåˆ° ComfyUI

    Args:
        session: HTTP ä¼šè¯
        endpoint: API ç«¯ç‚¹
        workflow: å·¥ä½œæµé…ç½®

    Returns:
        æç¤ºè¯ ID

    Raises:
        WorkflowSubmissionError: å·¥ä½œæµæäº¤å¤±è´¥
    """
    try:
        async with session.post(
            f"{endpoint}/prompt",
            json={"prompt": workflow},
            timeout=DEFAULT_TIMEOUT,
        ) as response:
            if response.status != 200:
                raise WorkflowSubmissionError(f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status}")

            data = await response.json()
            prompt_id = data.get("prompt_id")
            if not prompt_id:
                raise WorkflowSubmissionError("å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° prompt_id")

            logger.info(f"å·¥ä½œæµå·²æäº¤ï¼Œprompt_id: {prompt_id}")
            return prompt_id

    except ClientError as e:
        raise WorkflowSubmissionError(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
    except Exception as e:
        raise WorkflowSubmissionError(f"æäº¤å·¥ä½œæµæ—¶å‘ç”Ÿé”™è¯¯: {e}")


async def get_job_info(
    session: ClientSession, endpoint: str, job_id: str
) -> Dict[str, Any]:
    """
    è·å–ä»»åŠ¡ä¿¡æ¯

    Args:
        session: HTTP ä¼šè¯
        endpoint: API ç«¯ç‚¹
        job_id: ä»»åŠ¡ ID

    Returns:
        ä»»åŠ¡ä¿¡æ¯å­—å…¸
    """
    try:
        async with session.get(f"{endpoint}/history/{job_id}") as response:
            if response.status != 200:
                raise Exception(f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status}")

            return await response.json()

    except ClientError as e:
        raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")

    except Exception as e:
        raise Exception(f"è·å–ä»»åŠ¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")


async def _wait_for_image_generation(
    session: ClientSession, endpoint: str, prompt_id: str
) -> str:
    """
    ç­‰å¾…å›¾ç‰‡ç”Ÿæˆå®Œæˆå¹¶è·å–æ–‡ä»¶å

    Args:
        session: HTTP ä¼šè¯
        endpoint: API ç«¯ç‚¹
        prompt_id: æç¤ºè¯ ID

    Returns:
        ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶å

    Raises:
        ImageGenerationTimeoutError: ç”Ÿæˆè¶…æ—¶
    """
    for attempt in range(MAX_RETRIES):
        await asyncio.sleep(RETRY_DELAY)

        try:
            prompt_data = await get_job_info(session, endpoint, prompt_id)
    
            # è·å–ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶å
            outputs = prompt_data.get("outputs", {})
            if not outputs:
                logger.debug(
                    f"prompt_id {prompt_id} çš„è¾“å‡ºä¸ºç©ºï¼Œå°è¯• {attempt + 1}/{MAX_RETRIES}"
                )
                continue

            # è·å–ç¬¬ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„ç»“æœ
            for output_key, output_data in outputs.items():
                images = output_data.get("images", [])
                if images:
                    image_filename = images[0]["filename"]
                    logger.info(f"å›¾ç‰‡ç”Ÿæˆå®Œæˆ: {image_filename}")
                    return image_filename

            logger.debug(f"è¾“å‡ºä¸­æš‚æ— å›¾ç‰‡ï¼Œå°è¯• {attempt + 1}/{MAX_RETRIES}")

        except ClientError as e:
            logger.warning(
                f"æ£€æŸ¥ç”ŸæˆçŠ¶æ€æ—¶ç½‘ç»œé”™è¯¯: {e}, å°è¯• {attempt + 1}/{MAX_RETRIES}"
            )
        except Exception as e:
            logger.error(
                f"æ£€æŸ¥ç”ŸæˆçŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯: {e}, å°è¯• {attempt + 1}/{MAX_RETRIES}"
            )

    raise ImageGenerationTimeoutError(f"å›¾ç‰‡ç”Ÿæˆè¶…æ—¶ï¼Œå·²å°è¯• {MAX_RETRIES} æ¬¡")


async def _download_image(
    session: ClientSession, endpoint: str, filename: str, subfolder: str
) -> bytes:
    """
    ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡

    Args:
        session: HTTP ä¼šè¯
        endpoint: API ç«¯ç‚¹
        image_filename: å›¾ç‰‡æ–‡ä»¶å

    Returns:
        å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®

    Raises:
        ImageDownloadError: å›¾ç‰‡ä¸‹è½½å¤±è´¥
    """

    url = f"{endpoint}/view?filename={filename}&subfolder={subfolder}&type=output"

    try:
        async with session.get(url) as response:
            if response.status != 200:
                raise ImageDownloadError(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {response.status}, url: {url}")

            image_data = await response.read()
            logger.info(f" å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_data)} bytes, url:{url}")
            return image_data

    except ClientError as e:
        raise ImageDownloadError(f"ä¸‹è½½å›¾ç‰‡æ—¶ç½‘ç»œé”™è¯¯: {e}")


async def generate_image(
    endpoint: str,
    checkpoint: str,
    prompt: str,
    size: str = "1024x1024",
    steps: int = 16,
    cfg: float = 1.0,
    seed: Optional[int] = None,
) -> Optional[str]:
    """
    é€šè¿‡ ComfyUI API å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡

    Args:
        endpoint: ComfyUI API ç«¯ç‚¹
        checkpoint: æ£€æŸ¥ç‚¹æ¨¡å‹åç§°ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        prompt: ç”Ÿæˆå›¾ç‰‡çš„æ–‡æœ¬æè¿°
        size: å›¾ç‰‡å°ºå¯¸ï¼Œæ ¼å¼ä¸º "å®½xé«˜"ï¼Œå¦‚ "512x512"
        steps: é‡‡æ ·æ­¥æ•°ï¼Œé»˜è®¤ä¸º 12
        cfg: CFG scaleï¼Œé»˜è®¤ä¸º 1.0ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        seed: éšæœºç§å­ï¼Œå¦‚æœä¸º None åˆ™éšæœºç”Ÿæˆ

    Returns:
        å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å› None

    Raises:
        ValueError: å‚æ•°æ ¼å¼é”™è¯¯
        ComfyAPIError: API è°ƒç”¨ç›¸å…³é”™è¯¯
    """
    try:
        # è§£æå°ºå¯¸
        width, height = _parse_image_size(size)

        # åˆ›å»ºå·¥ä½œæµ
        workflow = _create_workflow(prompt, width, height, steps, seed)

        logger.info(f"å¼€å§‹ç”Ÿæˆå›¾ç‰‡: [{size}] {prompt}")

        # åˆ›å»º HTTP ä¼šè¯
        async with ClientSession(timeout=DEFAULT_TIMEOUT) as session:
            # æäº¤å·¥ä½œæµ
            return await _submit_workflow(session, endpoint, workflow)

    except (ComfyAPIError, ValueError):
        # é‡æ–°æŠ›å‡ºå·²çŸ¥çš„å¼‚å¸¸ç±»å‹
        raise
    except Exception as e:
        logger.exception(f"ç”Ÿæˆå›¾ç‰‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None


async def job_status(endpoint: str, job_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä»»åŠ¡çŠ¶æ€

    Args:
        endpoint: ComfyUI API ç«¯ç‚¹
        prompt_id: æç¤ºè¯ ID

    Returns:
        åŒ…å«ä»»åŠ¡çŠ¶æ€çš„å­—å…¸ï¼Œæˆ–åœ¨æ‰¾ä¸åˆ°æ—¶è¿”å› Noneã€‚
        å¯èƒ½çš„ 'status' å€¼: 'completed', 'running', 'pending', 'not_found'

    Raises:
        ComfyAPIError: API è°ƒç”¨ç›¸å…³é”™è¯¯
    """
    try:
        async with ClientSession(timeout=DEFAULT_TIMEOUT) as session:
            # æ£€æŸ¥å†å²è®°å½•ä¸­æ˜¯å¦å·²å®Œæˆ
            async with session.get(f"{endpoint}/history/{job_id}") as response:
                if response.status == 200:
                    history = await response.json()
                    if job_id in history:
                        logger.info(f"ä»»åŠ¡ {job_id} å·²å®Œæˆã€‚")
                        return {"status": "completed", "data": history[job_id]}
                elif response.status != 404:
                    logger.warning(f"è·å–å†å²è®°å½•å¤±è´¥: HTTP {response.status}")

            # å¦‚æœä¸åœ¨å†å²è®°å½•ä¸­ï¼Œæ£€æŸ¥é˜Ÿåˆ—
            async with session.get(f"{endpoint}/queue") as response:
                if response.status == 200:
                    queue_data = await response.json()

                    # æ£€æŸ¥æ­£åœ¨è¿è¡Œçš„é˜Ÿåˆ—
                    # item format: [prompt_number, prompt_id, prompt, extra_prompt_data, client_id]
                    for item in queue_data.get("queue_running", []):
                        if len(item) > 1 and item[1] == job_id:
                            logger.info(f"ä»»åŠ¡ {job_id} æ­£åœ¨è¿è¡Œã€‚")
                            return {"status": "running", "data": item}

                    # æ£€æŸ¥å¾…å¤„ç†çš„é˜Ÿåˆ—
                    for item in queue_data.get("queue_pending", []):
                        if len(item) > 1 and item[1] == job_id:
                            logger.info(f"ä»»åŠ¡ {job_id} æ­£åœ¨ç­‰å¾…ã€‚")
                            return {"status": "pending", "data": item}
                else:
                    logger.warning(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: HTTP {response.status}")

            logger.info(f"ä»»åŠ¡ {job_id} åœ¨å†å²è®°å½•æˆ–å½“å‰é˜Ÿåˆ—ä¸­æœªæ‰¾åˆ°ã€‚")
            return {"status": "not_found", "data": {}}

    except ClientError as e:
        raise ComfyAPIError(f"è·å–ä»»åŠ¡çŠ¶æ€æ—¶ç½‘ç»œé”™è¯¯: {e}") from e
    except Exception as e:
        raise ComfyAPIError(f"è·å–ä»»åŠ¡çŠ¶æ€æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}") from e


async def job_cancel(endpoint: str, job_id: str) -> bool:
    """
    å–æ¶ˆä»»åŠ¡

    Args:
        endpoint: ComfyUI API ç«¯ç‚¹
        job_id: ä»»åŠ¡ ID
    """
    try:
        async with ClientSession(timeout=DEFAULT_TIMEOUT) as session:
            async with session.post(f"{endpoint}/cancel/{job_id}") as response:
                if response.status == 200:
                    logger.info(f"ä»»åŠ¡ {job_id} å·²å–æ¶ˆã€‚")
                    return True
                else:
                    logger.warning(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: HTTP {response.status}")
                    return False
    except ClientError as e:
        raise ComfyAPIError(f"å–æ¶ˆä»»åŠ¡æ—¶ç½‘ç»œé”™è¯¯: {e}") from e


async def get_image_bytes(endpoint: str, job_id: str) -> Optional[bytes]:
    """
    è·å–å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®

    Args:
        endpoint: ComfyUI API ç«¯ç‚¹
        job_id: ä»»åŠ¡ ID
    """
    try:
        async with ClientSession(timeout=DEFAULT_TIMEOUT) as session:
            info = await get_job_info(session, endpoint, job_id)

            # get filename and subfolder
            filename = info.get("outputs", {}).get("images", [{}])[0].get("filename")
            subfolder = info.get("outputs", {}).get("images", [{}])[0].get("subfolder")
            
            # download image
            image_data = await _download_image(session, endpoint, filename, subfolder)

            return image_data
    except ClientError as e:
        raise ComfyAPIError(f"è·å–å›¾ç‰‡æ—¶ç½‘ç»œé”™è¯¯: {e}") from e
    except Exception as e:
        raise ComfyAPIError(f"è·å–å›¾ç‰‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}") from e
