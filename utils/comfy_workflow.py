WORKFLOWS = {
    "flux": {
        "6": {
            "inputs": {
                "text": "",
                "clip": ["44", 0],
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Positive Prompt)"},
        },
        "8": {
            "inputs": {"samples": ["13", 0], "vae": ["10", 0]},
            "class_type": "VAEDecode",
            "_meta": {"title": "VAE Decode"},
        },
        "10": {
            "inputs": {"vae_name": "ae.safetensors"},
            "class_type": "VAELoader",
            "_meta": {"title": "Load VAE"},
        },
        "13": {
            "inputs": {
                "noise": ["25", 0],
                "guider": ["22", 0],
                "sampler": ["16", 0],
                "sigmas": ["17", 0],
                "latent_image": ["27", 0],
            },
            "class_type": "SamplerCustomAdvanced",
            "_meta": {"title": "SamplerCustomAdvanced"},
        },
        "16": {
            "inputs": {"sampler_name": "euler_ancestral"},
            "class_type": "KSamplerSelect",
            "_meta": {"title": "KSamplerSelect"},
        },
        "17": {
            "inputs": {
                "scheduler": "sgm_uniform",
                "steps": 16,
                "denoise": 1,
                "model": ["30", 0],
            },
            "class_type": "BasicScheduler",
            "_meta": {"title": "BasicScheduler"},
        },
        "22": {
            "inputs": {"model": ["30", 0], "conditioning": ["26", 0]},
            "class_type": "BasicGuider",
            "_meta": {"title": "BasicGuider"},
        },
        "25": {
            "inputs": {"noise_seed": 733113376065330},
            "class_type": "RandomNoise",
            "_meta": {"title": "RandomNoise"},
        },
        "26": {
            "inputs": {"guidance": 2.1, "conditioning": ["6", 0]},
            "class_type": "FluxGuidance",
            "_meta": {"title": "FluxGuidance"},
        },
        "27": {
            "inputs": {"width": 832, "height": 1216, "batch_size": 1},
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "EmptySD3LatentImage"},
        },
        "30": {
            "inputs": {
                "max_shift": 1.15,
                "base_shift": 0.5,
                "width": 832,
                "height": 1216,
                "model": ["47", 0],
            },
            "class_type": "ModelSamplingFlux",
            "_meta": {"title": "ModelSamplingFlux"},
        },
        "44": {
            "inputs": {
                "model_type": "flux",
                "text_encoder1": "clip-vit-large-patch14/model.safetensors",
                "text_encoder2": "t5xxl_fp8_e4m3fn_scaled.safetensors",
                "t5_min_length": 512,
                "use_4bit_t5": "disable",
                "int4_model": "none",
            },
            "class_type": "NunchakuTextEncoderLoader",
            "_meta": {"title": "Nunchaku Text Encoder Loader (Deprecated)"},
        },
        "45": {
            "inputs": {
                "model_path": "svdq-int4-flux.1-dev",
                "cache_threshold": 0,
                "attention": "nunchaku-fp16",
                "cpu_offload": "auto",
                "device_id": 0,
                "data_type": "float16",
                "i2f_mode": "enabled",
            },
            "class_type": "NunchakuFluxDiTLoader",
            "_meta": {"title": "Nunchaku FLUX DiT Loader"},
        },
        "47": {
            "inputs": {
                "lora_name": "flux/aidmaHyperrealism-FLUX-v0.3-[aidmaHyperrealism].safetensors",
                "lora_strength": 0.8,
                "model": ["55", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX LoRA Loader"},
        },
        "50": {
            "inputs": {
                "filename_prefix": "api",
                "filename_keys": "sampler_name, cfg, steps, %F_%H-%M-%S",
                "foldername_prefix": "",
                "foldername_keys": "flux",
                "delimiter": "-",
                "save_job_data": "disabled",
                "job_data_per_image": False,
                "job_custom_text": "",
                "save_metadata": False,
                "counter_digits": 4,
                "counter_position": "last",
                "one_counter_per_folder": True,
                "image_preview": True,
                "output_ext": ".webp",
                "quality": 90,
                "images": ["53", 0],
            },
            "class_type": "SaveImageExtended",
            "_meta": {"title": "ðŸ’¾ Save Image Extended"},
        },
        "53": {
            "inputs": {"value": ["8", 0]},
            "class_type": "UnloadAllModels",
            "_meta": {"title": "UnloadAllModels"},
        },
        "55": {
            "inputs": {
                "lora_name": "flux/flux1-turbo.safetensors",
                "lora_strength": 0.6,
                "model": ["45", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX LoRA Loader"},
        },
    },
    "zimage": {
        "3": {
            "inputs": {
                "seed": 813197628083065,
                "steps": 8,
                "cfg": 1,
                "sampler_name": "euler_ancestral",
                "scheduler": "simple",
                "denoise": 1,
                "model": ["28", 0],
                "positive": ["6", 0],
                "negative": ["7", 0],
                "latent_image": ["13", 0],
            },
            "class_type": "KSampler",
            "_meta": {"title": "KSampler"},
        },
        "6": {
            "inputs": {
                "text": "",
                "clip": ["33", 0],
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Positive Prompt)"},
        },
        "7": {
            "inputs": {"text": "", "clip": ["33", 0]},
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Negative Prompt)"},
        },
        "8": {"inputs": {"samples": ["3", 0], "vae": ["17", 0]}, "class_type": "VAEDecode", "_meta": {"title": "VAE Decode"}},
        "13": {
            "inputs": {"width": ["29", 0], "height": ["29", 1], "batch_size": 1},
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "EmptySD3LatentImage"},
        },
        "17": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}},
        "28": {
            "inputs": {"sage_attention": "auto", "allow_compile": False, "model": ["52", 0]},
            "class_type": "PathchSageAttentionKJ",
            "_meta": {"title": "Patch Sage Attention KJ"},
        },
        "29": {
            "inputs": {
                "megapixel": "0.4",
                "aspect_ratio": "3:4 (Golden Ratio)",
                "divisible_by": "64",
                "custom_ratio": False,
                "custom_aspect_ratio": "1:1",
            },
            "class_type": "FluxResolutionNode",
            "_meta": {"title": "Flux Resolution Calc"},
        },
        "33": {
            "inputs": {"clip_name": "qwen3_4b_fp8_scaled.safetensors", "type": "lumina2", "device": "default"},
            "class_type": "CLIPLoader",
            "_meta": {"title": "Load CLIP"},
        },
        "37": {
            "inputs": {
                "filename": "%time_%basemodelname_%seed",
                "path": "/one/api/",
                "extension": "webp",
                "lossless_webp": True,
                "quality_jpeg_or_webp": 95,
                "optimize_png": False,
                "embed_workflow": True,
                "save_workflow_as_json": False,
                "counter": 0,
                "time_format": "%Y-%m-%d-%H%M%S",
                "show_preview": True,
                "images": ["46", 0],
            },
            "class_type": "Image Saver Simple",
            "_meta": {"title": "Image Saver Simple"},
        },
        "40": {
            "inputs": {
                "seed": 2916339138,
                "resolution": 1080,
                "max_resolution": 0,
                "batch_size": 5,
                "uniform_batch_size": False,
                "color_correction": "lab",
                "temporal_overlap": 0,
                "prepend_frames": 0,
                "input_noise_scale": 0,
                "latent_noise_scale": 0,
                "offload_device": "cpu",
                "enable_debug": False,
                "dit": ["42", 0],
                "vae": ["43", 0],
            },
            "class_type": "SeedVR2VideoUpscaler",
            "_meta": {"title": "SeedVR2 Video Upscaler (v2.5.15)"},
        },
        "41": {
            "inputs": {
                "backend": "cudagraphs",
                "mode": "default",
                "fullgraph": False,
                "dynamic": False,
                "dynamo_cache_size_limit": 64,
                "dynamo_recompile_limit": 128,
            },
            "class_type": "SeedVR2TorchCompileSettings",
            "_meta": {"title": "SeedVR2 Torch Compile Settings"},
        },
        "42": {
            "inputs": {
                "model": "seedvr2_ema_3b_fp8_e4m3fn.safetensors",
                "device": "cuda:0",
                "blocks_to_swap": 0,
                "swap_io_components": False,
                "offload_device": "cpu",
                "cache_model": True,
                "attention_mode": "sdpa",
                "torch_compile_args": ["41", 0],
            },
            "class_type": "SeedVR2LoadDiTModel",
            "_meta": {"title": "SeedVR2 (Down)Load DiT Model"},
        },
        "43": {
            "inputs": {
                "model": "ema_vae_fp16.safetensors",
                "device": "cuda:0",
                "encode_tiled": False,
                "encode_tile_size": 1024,
                "encode_tile_overlap": 128,
                "decode_tiled": False,
                "decode_tile_size": 1024,
                "decode_tile_overlap": 128,
                "tile_debug": "False",
                "offload_device": "none",
                "cache_model": False,
                "torch_compile_args": ["41", 0],
            },
            "class_type": "SeedVR2LoadVAEModel",
            "_meta": {"title": "SeedVR2 (Down)Load VAE Model"},
        },
        "46": {"inputs": {"value": ["8", 0]}, "class_type": "UnloadAllModels", "_meta": {"title": "UnloadAllModels"}},
        "47": {"inputs": {"value": ["40", 0]}, "class_type": "UnloadAllModels", "_meta": {"title": "UnloadAllModels"}},
        "52": {
            "inputs": {
                "model_name": "zimage/z_image_turbo-Q8_0.gguf",
                "extra_model_name": "none",
                "dequant_dtype": "default",
                "patch_dtype": "default",
                "patch_on_device": False,
                "enable_fp16_accumulation": False,
                "attention_override": "sageattn",
            },
            "class_type": "GGUFLoaderKJ",
            "_meta": {"title": "GGUFLoaderKJ"},
        },
    },
}
