WORKFLOWS = {
    "flux": {
        "6": {
            "inputs": {
                "text": "",
                "clip": ["44", 0],
            },
            "class_type": "CLIPTextEncode",
            "_meta": {"title": "CLIP Text Encode (Positive Prompt)"},
        },
        "8": {
            "inputs": {"samples": ["13", 0], "vae": ["10", 0]},
            "class_type": "VAEDecode",
            "_meta": {"title": "VAE Decode"},
        },
        "10": {
            "inputs": {"vae_name": "ae.safetensors"},
            "class_type": "VAELoader",
            "_meta": {"title": "Load VAE"},
        },
        "13": {
            "inputs": {
                "noise": ["25", 0],
                "guider": ["22", 0],
                "sampler": ["16", 0],
                "sigmas": ["17", 0],
                "latent_image": ["27", 0],
            },
            "class_type": "SamplerCustomAdvanced",
            "_meta": {"title": "SamplerCustomAdvanced"},
        },
        "16": {
            "inputs": {"sampler_name": "euler_ancestral"},
            "class_type": "KSamplerSelect",
            "_meta": {"title": "KSamplerSelect"},
        },
        "17": {
            "inputs": {
                "scheduler": "sgm_uniform",
                "steps": 16,
                "denoise": 1,
                "model": ["30", 0],
            },
            "class_type": "BasicScheduler",
            "_meta": {"title": "BasicScheduler"},
        },
        "22": {
            "inputs": {"model": ["30", 0], "conditioning": ["26", 0]},
            "class_type": "BasicGuider",
            "_meta": {"title": "BasicGuider"},
        },
        "25": {
            "inputs": {"noise_seed": 733113376065330},
            "class_type": "RandomNoise",
            "_meta": {"title": "RandomNoise"},
        },
        "26": {
            "inputs": {"guidance": 2.1, "conditioning": ["6", 0]},
            "class_type": "FluxGuidance",
            "_meta": {"title": "FluxGuidance"},
        },
        "27": {
            "inputs": {"width": 832, "height": 1216, "batch_size": 1},
            "class_type": "EmptySD3LatentImage",
            "_meta": {"title": "EmptySD3LatentImage"},
        },
        "30": {
            "inputs": {
                "max_shift": 1.15,
                "base_shift": 0.5,
                "width": 832,
                "height": 1216,
                "model": ["47", 0],
            },
            "class_type": "ModelSamplingFlux",
            "_meta": {"title": "ModelSamplingFlux"},
        },
        "44": {
            "inputs": {
                "model_type": "flux",
                "text_encoder1": "clip-vit-large-patch14/model.safetensors",
                "text_encoder2": "t5xxl_fp8_e4m3fn_scaled.safetensors",
                "t5_min_length": 512,
                "use_4bit_t5": "disable",
                "int4_model": "none",
            },
            "class_type": "NunchakuTextEncoderLoader",
            "_meta": {"title": "Nunchaku Text Encoder Loader (Deprecated)"},
        },
        "45": {
            "inputs": {
                "model_path": "svdq-int4-flux.1-dev",
                "cache_threshold": 0,
                "attention": "nunchaku-fp16",
                "cpu_offload": "auto",
                "device_id": 0,
                "data_type": "float16",
                "i2f_mode": "enabled",
            },
            "class_type": "NunchakuFluxDiTLoader",
            "_meta": {"title": "Nunchaku FLUX DiT Loader"},
        },
        "47": {
            "inputs": {
                "lora_name": "flux/aidmaHyperrealism-FLUX-v0.3-[aidmaHyperrealism].safetensors",
                "lora_strength": 0.8,
                "model": ["55", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX LoRA Loader"},
        },
        "50": {
            "inputs": {
                "filename_prefix": "api",
                "filename_keys": "sampler_name, cfg, steps, %F_%H-%M-%S",
                "foldername_prefix": "",
                "foldername_keys": "flux",
                "delimiter": "-",
                "save_job_data": "disabled",
                "job_data_per_image": False,
                "job_custom_text": "",
                "save_metadata": False,
                "counter_digits": 4,
                "counter_position": "last",
                "one_counter_per_folder": True,
                "image_preview": True,
                "output_ext": ".webp",
                "quality": 90,
                "images": ["53", 0],
            },
            "class_type": "SaveImageExtended",
            "_meta": {"title": "ðŸ’¾ Save Image Extended"},
        },
        "53": {
            "inputs": {"value": ["8", 0]},
            "class_type": "UnloadAllModels",
            "_meta": {"title": "UnloadAllModels"},
        },
        "55": {
            "inputs": {
                "lora_name": "flux/flux1-turbo.safetensors",
                "lora_strength": 0.6,
                "model": ["45", 0],
            },
            "class_type": "NunchakuFluxLoraLoader",
            "_meta": {"title": "Nunchaku FLUX LoRA Loader"},
        },
    },
    "zimage": {
            "3": {
                "inputs": {
                    "seed": 234578258190155,
                    "steps": 8,
                    "cfg": 1,
                    "sampler_name": "euler_ancestral",
                    "scheduler": "sgm_uniform",
                    "denoise": 1,
                    "model": ["28", 0],
                    "positive": ["6", 0],
                    "negative": ["7", 0],
                    "latent_image": ["13", 0],
                },
                "class_type": "KSampler",
                "_meta": {"title": "KSampler"},
            },
            "6": {
                "inputs": {"text": "", "clip": ["33", 0]},
                "class_type": "CLIPTextEncode",
                "_meta": {"title": "CLIP Text Encode (Positive Prompt)"},
            },
            "7": {
                "inputs": {"text": "", "clip": ["33", 0]},
                "class_type": "CLIPTextEncode",
                "_meta": {"title": "CLIP Text Encode (Negative Prompt)"},
            },
            "8": {
                "inputs": {"samples": ["3", 0], "vae": ["17", 0]},
                "class_type": "VAEDecode",
                "_meta": {"title": "VAE Decode"},
            },
            "13": {
                "inputs": {"width": ["29", 0], "height": ["29", 1], "batch_size": 1},
                "class_type": "EmptySD3LatentImage",
                "_meta": {"title": "EmptySD3LatentImage"},
            },
            "16": {
                "inputs": {"unet_name": "zimage/z-image-turbo-fp8-e5m2.safetensors", "weight_dtype": "fp8_e5m2"},
                "class_type": "UNETLoader",
                "_meta": {"title": "Load Diffusion Model"},
            },
            "17": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}},
            "28": {
                "inputs": {"sage_attention": "auto", "allow_compile": False, "model": ["16", 0]},
                "class_type": "PathchSageAttentionKJ",
                "_meta": {"title": "Patch Sage Attention KJ"},
            },
            "29": {
                "inputs": {
                    "megapixel": "1.0",
                    "aspect_ratio": "3:4 (Golden Ratio)",
                    "divisible_by": "64",
                    "custom_ratio": False,
                    "custom_aspect_ratio": "1:1",
                },
                "class_type": "FluxResolutionNode",
                "_meta": {"title": "Flux Resolution Calc"},
            },
            "32": {
                "inputs": {"clip_name": "Qwen_3_4b-Q8_0.gguf", "type": "lumina2"},
                "class_type": "CLIPLoaderGGUF",
                "_meta": {"title": "CLIPLoader (GGUF)"},
            },
            "33": {
                "inputs": {"clip_name": "qwen3_4b_fp8_scaled.safetensors", "type": "lumina2", "device": "default"},
                "class_type": "CLIPLoader",
                "_meta": {"title": "Load CLIP"},
            },
            "37": {
                "inputs": {
                    "filename": "%time_%basemodelname_%seed",
                    "path": "api/",
                    "extension": "webp",
                    "lossless_webp": True,
                    "quality_jpeg_or_webp": 90,
                    "optimize_png": False,
                    "embed_workflow": True,
                    "save_workflow_as_json": False,
                    "counter": 0,
                    "time_format": "%Y-%m-%d-%H%M%S",
                    "show_preview": True,
                    "images": ["8", 0],
                },
                "class_type": "Image Saver Simple",
                "_meta": {"title": "Image Saver Simple"},
            },
    },
}
